<<<<<<< HEAD
with open("01.txt.txt", "r") as file:
    content = file.read()

print(content)
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c4016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': 1, 'days': 1, \"nasa's\": 1, 'cassini': 2, 'spacecraft': 1, 'will': 1, 'nosedive': 1, 'into': 1, 'saturn': 2, 'and': 4, 'burn': 1, 'up': 1, \"planet's\": 1, 'atmosphere': 1, \"it's\": 2, 'final': 1, 'suicidal': 1, 'step': 1, 'a': 2, 'monthslong': 1, 'dance': 1, \"saturn's\": 1, 'rings': 1, 'has': 2, 'given': 1, 'scientists': 1, 'unprecedented': 1, 'view': 1, 'sixth': 1, 'planet': 1, 'from': 1, 'sun': 1, 'also': 1, 'the': 3, 'end': 2, 'mission': 1, 'revolutionized': 1, 'understanding': 1, 'opened': 1, 'eyes': 1, 'to': 2, 'two': 1, 'worlds': 1, 'could': 1, 'be': 1, 'home': 1, 'alien': 1, 'life': 1, 'moons': 1, 'titan': 1, 'enceladus': 1, 'really': 1, 'an': 1, 'era': 1, 'fans': 1, 'are': 1, 'devastated': 1}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "#change this to search?\n",
    "def clean_text_file(filepath, encoding=\"utf-8\"):\n",
    "    punctuation = string.punctuation.replace(\"'\", \"\")\n",
    "    translator = str.maketrans(\"\", \"\", punctuation)\n",
    "\n",
    "    file_words = []\n",
    "    with open(filepath, \"r\", encoding=encoding, errors=\"ignore\") as file:\n",
    "        for line in file:\n",
    "            line = line.lower().strip()\n",
    "            line = line.translate(translator)\n",
    "            file_words.extend(line.split())\n",
    "        \n",
    "    for word in file_words:\n",
    "        if word in stop_words:\n",
    "            file_words.remove(word)\n",
    "    return file_words\n",
    "\n",
    "\n",
    "#without lambda\n",
    "def index(words):\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "    return word_freq\n",
    "\n",
    "#with lambda\n",
    "def index_lambda(words):\n",
    "    word_freq = {}\n",
    "    counter = lambda w: word_freq.update({w: word_freq.get(w, 0) + 1})\n",
    "    for word in words:\n",
    "        counter(word)\n",
    "    return word_freq\n",
    "\n",
    "stop_words = clean_text_file(\"stopwords.txt\")\n",
    "file1_words = clean_text_file(\"01.txt.txt\")\n",
    "file2_words = clean_text_file(\"02.txt.txt\")\n",
    "file3_words = clean_text_file(\"03.txt.txt\")\n",
    "file4_words = clean_text_file(\"04.txt.txt\")\n",
    "file5_words = clean_text_file(\"05.txt.txt\")\n",
    "file6_words = clean_text_file(\"06.txt.txt\")\n",
    "file7_words = clean_text_file(\"07.txt.txt\")\n",
    "file8_words = clean_text_file(\"08.txt.txt\")\n",
    "file9_words = clean_text_file(\"09.txt.txt\")\n",
    "file10_words = clean_text_file(\"10.txt.txt\")\n",
    "file11_words = clean_text_file(\"11.txt.txt\")\n",
    "file12_words = clean_text_file(\"12.txt.txt\")\n",
    "file13_words = clean_text_file(\"13.txt.txt\")\n",
    "file14_words = clean_text_file(\"14.txt.txt\")\n",
    "file15_words = clean_text_file(\"15.txt.txt\")\n",
    "file16_words = clean_text_file(\"16.txt.txt\")\n",
    "file17_words = clean_text_file(\"17.txt.txt\")\n",
    "file18_words = clean_text_file(\"18.txt.txt\")\n",
    "file19_words = clean_text_file(\"19.txt.txt\")\n",
    "file20_words = clean_text_file(\"20.txt.txt\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 4934652 (Index and Search functions are made, just need to add comments and add scoring for query)
